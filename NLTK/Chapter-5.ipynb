{
 "metadata": {
  "name": "",
  "signature": "sha256:e768273f614218934083a5b0260e95e614378279601ce8dd0a2fe39c1597c198"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Categorizing and Tagging Words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NLP Pipeline - Tokenization > Tagging**  \n",
      "\n",
      "\n",
      "**<font color = 'blue'>Tagging</font>** - Process of classifying words into their **parts of speech** and labeling them accordingly. Also known as _part-of-speech tagging or POS-tagging_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using a Tagger\n",
      "\n",
      "**<font color = 'blue'>nltk.pos_tag(tokens)</font>** - Returns tuple: (token, tag)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
      "print nltk.pos_tag(text) # Refuse: Verb and Noun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**<font color = 'blue'>nltk.tag.str2tuple('token/tag')</font>** - Create (token, tag) tuples from the standard string representation of a tagged token."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
      "print tagged_token"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('fly', 'NN')\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**<font color = 'blue'>Nouns</font>** - Generally refer to people, places, things or concepts  \n",
      "**<font color = 'blue'>Verbs</font>** - Words that describe events and actions  \n",
      "**<font color = 'blue'>Adjectives and Adverbs</font>** - Adjectives describes nouns, and can be used as modifiers or in predicates. Adverbs modify verbs to specify the time, manner, place or direction of the event described by the verb."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#####Experiment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('document.txt')\n",
      "raw = f.read()\n",
      "tokens = nltk.word_tokenize(raw)\n",
      "print tokens[:10]\n",
      "tagged_tokens = nltk.pos_tag(tokens)\n",
      "print tagged_tokens[:5]\n",
      "cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_tokens)\n",
      "print list(cfd['VBN'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['According', 'to', 'legend', ',', 'the', 'Night', \"'s\", 'King', 'lived', 'during']\n",
        "[('According', 'VBG'), ('to', 'TO'), ('legend', 'VB'), (',', ','), ('the', 'DT')]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['cold']\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Schoolhouse Rock!** - Grammar Videos  \n",
      "\n",
      "**High Frequency POS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags = [b[1] for (a, b) in nltk.bigrams(tagged_tokens)]\n",
      "fd = nltk.FreqDist(tags)\n",
      "print tags[:5]\n",
      "fd.tabulate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['TO', 'VB', ',', 'DT', 'NNP']\n",
        "  IN   NN  VBD  NNP   DT  PRP    , PRP$    .   JJ   CC   RB   ``  POS   ''   TO  NNS   VB  WRB  VBN \n",
        "  13   11   10   10    8    7    4    4    4    3    3    3    2    2    2    2    2    1    1    1 \n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process(sentence):\n",
      "    for (w1, t1), (w2, t2), (w3, t3) in nltk.trigrams(sentence):\n",
      "        print w1, w2, w3\n",
      "\n",
      "text = 'This is a fancy restaurant.'\n",
      "sent = nltk.pos_tag(nltk.word_tokenize(text))\n",
      "process(sent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This is a\n",
        "is a fancy\n",
        "a fancy restaurant\n",
        "fancy restaurant .\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((word.lower(), tag) for (word, tag) in tagged_tokens)\n",
      "for word in sorted(cfd.conditions()):\n",
      "    if len(cfd[word]) > 1:\n",
      "        tags = [tag for tag, _ in cfd[word].most_common()]\n",
      "        print word, ' '.join(tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "her PRP$ PRP\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Mapping Words to Properties using Python Dictionaries  \n",
      "**Dictionary: {Key : Value}** or **dict(Key : Value)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = {} # Empty dictionary\n",
      "pos['colorless'] = 'ADJ' # Adding an entry\n",
      "print pos\n",
      "pos['ideas'] = 'N'\n",
      "pos['sleep'] = 'V'\n",
      "print pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'colorless': 'ADJ'}\n",
        "{'sleep': 'V', 'ideas': 'N', 'colorless': 'ADJ'}\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = dict(colorless = 'ADJ', ideas = 'N', sleep = 'V')\n",
      "pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V'}"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Using Key to retrieve Value** ```dictionary[key] ```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos['sleep']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "'V'"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Key with multiple Values**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos['sleep'] = ['V', 'N']\n",
      "print pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'sleep': ['V', 'N'], 'ideas': 'N', 'colorless': 'ADJ'}\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Convert dictionary to a list** - list of keys"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 118,
       "text": [
        "['sleep', 'ideas', 'colorless']"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Dictionary Methods: <font color = 'blue'>keys( ), values( ), items( )</font>** - Allows to access the keys, values and key-value pairs as separate lists."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pos.keys()\n",
      "print pos.values()\n",
      "print pos.items()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['sleep', 'ideas', 'colorless']\n",
        "[['V', 'N'], 'N', 'ADJ']\n",
        "[('sleep', ['V', 'N']), ('ideas', 'N'), ('colorless', 'ADJ')]\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Default Dictionaries** - Accessing a key that is not in a dictionary gives an error. Use ```defaultdict``` and supply a parameter which can be used to create the default value, e.g. ```int, float, str, list, dict, tuple```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "freq = defaultdict(int)\n",
      "freq['m'] = 3\n",
      "print freq['n'] # Key not in the dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> - Lambda"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = lambda: 'NOUN'\n",
      "f()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "'NOUN'"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = defaultdict(int)\n",
      "for word, tag in tagged_tokens:\n",
      "    counts[tag] += 1\n",
      "    \n",
      "print counts\n",
      "from operator import itemgetter\n",
      "print sorted(counts.items(), key = itemgetter(1), reverse = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<type 'int'>, {'VB': 1, 'VBG': 1, 'JJ': 3, 'NN': 11, 'VBD': 10, 'CC': 3, 'VBN': 1, '``': 2, ',': 4, 'POS': 2, \"''\": 2, 'TO': 2, 'PRP$': 4, 'PRP': 7, 'RB': 3, 'IN': 13, 'WRB': 1, 'DT': 8, '.': 4, 'NNS': 2, 'NNP': 10})\n",
        "[('IN', 13), ('NN', 11), ('VBD', 10), ('NNP', 10), ('DT', 8), ('PRP', 7), (',', 4), ('PRP$', 4), ('.', 4), ('JJ', 3), ('CC', 3), ('RB', 3), ('``', 2), ('POS', 2), (\"''\", 2), ('TO', 2), ('NNS', 2), ('VB', 1), ('VBG', 1), ('VBN', 1), ('WRB', 1)]\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**<font color = 'blue'>nltk.Index(pair)</font>** - More convinient way of creating a ```defaultdict(list)```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "anagrams = nltk.Index((''.join(sorted(w)), w) for w in tokens)\n",
      "anagrams['elov']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "['love']"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Reverse Lookup: Using Value to retrieve Key** - Construct a dictionary that maps values to keys: dict(Value : Key).  \n",
      "\n",
      "<font color = 'red'>_This does not work when multiple keys have same value_</font> - Use ```nltk.Index( )```  \n",
      "```.update( )``` - Method to add key : value pairs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = dict(colorless = 'ADJ', ideas = 'N', sleep = 'V')\n",
      "pos_r = dict((value, key) for key, value in pos.items())\n",
      "print pos_r['N']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ideas\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos.update({'cats': 'N', 'scratch': 'V'})\n",
      "pos_r = nltk.Index((value, key) for (key, value) in pos.items())\n",
      "print pos_r['V']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['scratch', 'sleep']\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Automatic Tagging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('document.txt')\n",
      "raw = f.read()\n",
      "tokens = nltk.word_tokenize(raw)\n",
      "print tokens[:10]\n",
      "\n",
      "# Gold Standard for Automatic Tagging Evaluation\n",
      "from nltk.corpus import brown\n",
      "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
      "brown_sents = brown.sents(categories = 'news')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['According', 'to', 'legend', ',', 'the', 'Night', \"'s\", 'King', 'lived', 'during']\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Default Tagger\n",
      "\n",
      "**<font color = 'blue'>nltk.DefaultTagger(POS Tag)</font>** - Assign a given POS tag to every single word.  \n",
      "**<font color = 'blue'>.tag(tokens)</font>** - Method to tag tokens "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
      "tokens = nltk.word_tokenize(r)\n",
      "default_tagger = nltk.DefaultTagger('IN')\n",
      "print default_tagger.tag(tokens)\n",
      "print default_tagger.evaluate(brown_tagged_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('I', 'IN'), ('do', 'IN'), ('not', 'IN'), ('like', 'IN'), ('green', 'IN'), ('eggs', 'IN'), ('and', 'IN'), ('ham', 'IN'), (',', 'IN'), ('I', 'IN'), ('do', 'IN'), ('not', 'IN'), ('like', 'IN'), ('them', 'IN'), ('Sam', 'IN'), ('I', 'IN'), ('am', 'IN'), ('!', 'IN')]\n",
        "0.105575113869"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Regular Expression Tagger\n",
      "\n",
      "**<font color = 'blue'>nltk.RegexpTagger(patterns)</font>** - Assigns tags to tokens on the basis of matching patterns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(raw)\n",
      "print nltk.pos_tag(tokens)[:10]\n",
      "\n",
      "patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD')]\n",
      "regexp_tagger = nltk.RegexpTagger(patterns)\n",
      "print regexp_tagger.tag(tokens)[:10] # Method to tag tokens\n",
      "regexp_tagger.evaluate(brown_tagged_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('According', 'VBG'), ('to', 'TO'), ('legend', 'VB'), (',', ','), ('the', 'DT'), ('Night', 'NNP'), (\"'s\", 'POS'), ('King', 'NNP'), ('lived', 'VBD'), ('during', 'IN')]\n",
        "[('According', 'VBG'), ('to', None), ('legend', None), (',', None), ('the', None), ('Night', None), (\"'s\", None), ('King', 'VBG'), ('lived', 'VBD'), ('during', 'VBG')]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "0.02820375121825089"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Lookup Tagger  \n",
      "- As Model size (lookup table size) increases the performance initially increases rapidly, eventually reaching a plateau\n",
      "\n",
      "**<font color = 'blue'>nltk.UnigramTagger(model, backoff = nltk.DefaultTagger(POS Tag)</font>** - Assigns tags to tokens on the basis of model or lookup table, backoff (Default Tagger) is used if the Lookup Tagger is unable to assign a tag i.e. tag = 'None' is assigned.  \n",
      "\n",
      "\n",
      "**Backoff** - Method for combining models: when a more specialized model (such as a bigram tagger) cannot assign a tag in a given context, we backoff to a more general model (such as a unigram tagger)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('document.txt')\n",
      "tokens = nltk.word_tokenize(f.read())\n",
      "fd = nltk.FreqDist(tokens)\n",
      "tagged_tokens = nltk.pos_tag(tokens)\n",
      "cfd = nltk.ConditionalFreqDist(tagged_tokens)\n",
      "most_freq_words = fd.most_common(5)\n",
      "likely_tags = dict((word, cfd[word].max()) for word, _ in most_freq_words)\n",
      "baseline_tagger = nltk.UnigramTagger(model = likely_tags)\n",
      "baseline_tagger.evaluate(brown_tagged_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "0.09107544205103725"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Evaluation** - To evaluate the performance of a tagger relative to the tags a human expert would assign, use a **<font color = 'blue'>gold standard</font>** test data - A corpus which has been manually annotated and which is accepted as a standard against which the guesses of an automatic system are assessed. e.g. <font color = 'blue'>baseline_tagger.evaluate(brown_tagged_sents)</font>  \n",
      "```python\n",
      "from nltk.corpus import brown\n",
      "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### N-Gram Tagging\n",
      "\n",
      "- Unigram taggers: Simple statistical algorithm - For each token assign the tag that is most likely for that particular token"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = \"According to legend, the Night's King lived during the Age of Heroes, not long after the Wall was complete. He was a fearless warrior named the thirteenth Lord Commander of the Night's Watch.\"\n",
      "tokens = r.split()\n",
      "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents) # Training Unigram Tagger\n",
      "test = unigram_tagger.tag(tokens) # Tagging new sentence\n",
      "unigram_tagger.evaluate(brown_tagged_sents) # Evaluating "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "0.9349006503968017"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Training and Testing Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = int(len(brown_tagged_sents) * 0.9)\n",
      "train_sents = brown_tagged_sents[:size]\n",
      "test_sents = brown_tagged_sents[size:]\n",
      "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
      "unigram_tagger.evaluate(test_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "0.8120203329014253"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**N-Gram Tagging** - A generalization of a Unigram Tagger whose context is the current word together with the part-of-speech tags of the  _n - 1_  preceding tokens. N-Gram tagger picks the tag that is most likely in the given context. ```NgramTagger``` class uses a tagged training corpus to determine which part-of-speech tag is most likely for each context.  \n",
      "\n",
      "**<font color = 'blue'>nltk.BigramTagger(training set)</font>**  \n",
      "**<font color = 'blue'>nltk.TrigramTagger(training set)</font>**\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_tagger = nltk.BigramTagger(train_sents) # Training Tagger\n",
      "bigram_tagger.tag(tokens) # Tagging Untagged Sentences\n",
      "bigram_tagger.evaluate(test_sents) # Evaluating Taggers Accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "0.10276088906608193"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Combining Taggers** - To address the trade-off between accuracy and coverage (sparse data problem - contexts that were not present in training data) is to use more accurate algorithms and to fall back on algorithms with wider coverage when necessary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = nltk.DefaultTagger('NN')\n",
      "t1 = nltk.UnigramTagger(train_sents, backoff = t0)\n",
      "t2 = nltk.BigramTagger(train_sents, backoff = t1)\n",
      "t2.evaluate(test_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "0.844911791089405"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Storing Taggers** - Saving a trained tagger in a file for later use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pickle import dump\n",
      "output = open('t2.pk1', 'wb')\n",
      "dump(t2, output, -1)\n",
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading saved tagger"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pickle import load\n",
      "input = open('t2.pk1', 'rb')\n",
      "tagger = load(input)\n",
      "input.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use loaded tagger for tagging"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"\"\"The board's action shows what free enterprise \n",
      "        is up against in our complex maze of regulatory laws.\"\"\"\n",
      "tokens = text.split()\n",
      "print tagger.tag(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('The', u'AT'), (\"board's\", u'NN$'), ('action', 'NN'), ('shows', u'NNS'), ('what', u'WDT'), ('free', u'JJ'), ('enterprise', 'NN'), ('is', u'BEZ'), ('up', u'RP'), ('against', u'IN'), ('in', u'IN'), ('our', u'PP$'), ('complex', u'JJ'), ('maze', 'NN'), ('of', u'IN'), ('regulatory', 'NN'), ('laws.', 'NN')]\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Performance Limitations** - ```Confusion Matrix```  \n",
      "**<font color = 'blue'>nltk.ConfusionMatrix(gold set, test set)</font>**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_tags = [tag for sent in brown.sents(categories='editorial') for (word, tag) in t2.tag(sent)]\n",
      "gold_tags = [tag for (word, tag) in brown.tagged_words(categories='editorial')]\n",
      "nltk.ConfusionMatrix(gold_tags, test_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "<ConfusionMatrix: 52061/61604 correct>"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Transformation-Based Tagging  \n",
      "\n",
      "- Potential issue with n-gram taggers is the size of their n-gram table (language model) - n > 3: Large sparse arrays\n",
      "- **Brill tagging** - Transformation-Based Learning: Guess the tag of each word, then go back and fix the mistakes. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}