{
 "metadata": {
  "name": "",
  "signature": "sha256:6bd8a6242f23f581f0ed848f992b6d7bdb855254d9304dae76535e1b74606e13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Gutenberg Corpus** \n",
      "\n",
      "File identifers in project Gutenberg corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.corpus.gutenberg.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'austen-emma.txt', u'austen-persuasion.txt', u'austen-sense.txt', u'bible-kjv.txt', u'blake-poems.txt', u'bryant-stories.txt', u'burgess-busterbrown.txt', u'carroll-alice.txt', u'chesterton-ball.txt', u'chesterton-brown.txt', u'chesterton-thursday.txt', u'edgeworth-parents.txt', u'melville-moby_dick.txt', u'milton-paradise.txt', u'shakespeare-caesar.txt', u'shakespeare-hamlet.txt', u'shakespeare-macbeth.txt', u'whitman-leaves.txt']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Accessing Gutenberg Corpus Texts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
      "len(emma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "192427"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color='blue'>**nltk.Text( )**</font>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emma = nltk.Text(emma)\n",
      "emma.concordance(\"displeasure\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 6 of 6 matches:\n",
        "and spoken with a degree of grave displeasure which Emma thought might be safel\n",
        "ally looked red with surprize and displeasure , as he stood up , in tall indign\n",
        "id he , in a voice of very strong displeasure , \" would do as well to keep his \n",
        "ill , with a look of surprize and displeasure .-- \" That is easy -- but Miss Fa\n",
        "feel some surprise , and a little displeasure , on hearing from Mr . Weston tha\n",
        "al of very reasonable , very just displeasure I had to persuade away . But it i\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import gutenberg\n",
      "gutenberg.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[u'austen-emma.txt',\n",
        " u'austen-persuasion.txt',\n",
        " u'austen-sense.txt',\n",
        " u'bible-kjv.txt',\n",
        " u'blake-poems.txt',\n",
        " u'bryant-stories.txt',\n",
        " u'burgess-busterbrown.txt',\n",
        " u'carroll-alice.txt',\n",
        " u'chesterton-ball.txt',\n",
        " u'chesterton-brown.txt',\n",
        " u'chesterton-thursday.txt',\n",
        " u'edgeworth-parents.txt',\n",
        " u'melville-moby_dick.txt',\n",
        " u'milton-paradise.txt',\n",
        " u'shakespeare-caesar.txt',\n",
        " u'shakespeare-hamlet.txt',\n",
        " u'shakespeare-macbeth.txt',\n",
        " u'whitman-leaves.txt']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emma = gutenberg.words('austen-emma.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# .raw() -> Gives contents of file without any linguistic processing. Includes spaces between the words\n",
      "# .sents()-> Divides text up into its sentences (list of words)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for fileid in gutenberg.fileids():\n",
      "    num_chars = len(gutenberg.raw(fileid)) # Avg. Word Length\n",
      "    num_words = len(gutenberg.words(fileid)) # Avg. Sentence Length\n",
      "    num_sents = len(gutenberg.sents(fileid)) # Lexical Diversity Score (No. of times each vocab item appears in the text)\n",
      "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
      "    print (round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4.0, 24.0, 26.0, u'austen-emma.txt')\n",
        "(4.0, 26.0, 16.0, u'austen-persuasion.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 28.0, 22.0, u'austen-sense.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 33.0, 79.0, u'bible-kjv.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 19.0, 5.0, u'blake-poems.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 19.0, 14.0, u'bryant-stories.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 17.0, 12.0, u'burgess-busterbrown.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 20.0, 12.0, u'carroll-alice.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 20.0, 11.0, u'chesterton-ball.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 22.0, 11.0, u'chesterton-brown.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 18.0, 10.0, u'chesterton-thursday.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 20.0, 24.0, u'edgeworth-parents.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 25.0, 15.0, u'melville-moby_dick.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 52.0, 10.0, u'milton-paradise.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 11.0, 8.0, u'shakespeare-caesar.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 12.0, 7.0, u'shakespeare-hamlet.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 12.0, 6.0, u'shakespeare-macbeth.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(4.0, 36.0, 12.0, u'whitman-leaves.txt')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
      "macbeth_sentences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[[u'[', u'The', u'Tragedie', u'of', u'Macbeth', u'by', u'William', u'Shakespeare', u'1603', u']'], [u'Actus', u'Primus', u'.'], ...]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "longest_len = max(len(s) for s in macbeth_sentences)\n",
      "print longest_len"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "158\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = [s for s in macbeth_sentences if len(s) == longest_len]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Webtext: Firefox forum, Conversations overheard in NYC, Movie Script, Advertisement, Wine Reviews\n",
      "from nltk.corpus import webtext\n",
      "for fileid in webtext.fileids():\n",
      "    print (fileid, webtext.raw(fileid)[:65], '...')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'firefox.txt', u'Cookie Manager: \"Don\\'t allow sites that set removed cookies to se', '...')\n",
        "(u'grail.txt', u'SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop', '...')\n",
        "(u'overheard.txt', u'White guy: So, do you have any plans for this evening?\\nAsian girl', '...')\n",
        "(u'pirates.txt', u\"PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr\", '...')\n",
        "(u'singles.txt', u'25 SEXY MALE, seeks attrac older single lady, for discreet encoun', '...')\n",
        "(u'wine.txt', u'Lovely delicate, fragrant Rhone wine. Polished leather and strawb', '...')\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instant Messaging Chat \n",
      "from nltk.corpus import nps_chat\n",
      "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
      "chatroom[123]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[u'i',\n",
        " u'do',\n",
        " u\"n't\",\n",
        " u'want',\n",
        " u'hot',\n",
        " u'pics',\n",
        " u'of',\n",
        " u'a',\n",
        " u'female',\n",
        " u',',\n",
        " u'I',\n",
        " u'can',\n",
        " u'look',\n",
        " u'in',\n",
        " u'a',\n",
        " u'mirror',\n",
        " u'.']"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "brown.categories()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "[u'adventure',\n",
        " u'belles_lettres',\n",
        " u'editorial',\n",
        " u'fiction',\n",
        " u'government',\n",
        " u'hobbies',\n",
        " u'humor',\n",
        " u'learned',\n",
        " u'lore',\n",
        " u'mystery',\n",
        " u'news',\n",
        " u'religion',\n",
        " u'reviews',\n",
        " u'romance',\n",
        " u'science_fiction']"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.words(categories = 'mystery')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[u'There', u'were', u'thirty-eight', u'patients', ...]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.words(fileids = ['cg22'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[u'Does', u'our', u'society', u'have', u'a', ...]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown.sents(categories = ['news', 'editorial', 'reviews'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "[[u'The', u'Fulton', u'County', u'Grand', u'Jury', u'said', u'Friday', u'an', u'investigation', u'of', u\"Atlanta's\", u'recent', u'primary', u'election', u'produced', u'``', u'no', u'evidence', u\"''\", u'that', u'any', u'irregularities', u'took', u'place', u'.'], [u'The', u'jury', u'further', u'said', u'in', u'term-end', u'presentments', u'that', u'the', u'City', u'Executive', u'Committee', u',', u'which', u'had', u'over-all', u'charge', u'of', u'the', u'election', u',', u'``', u'deserves', u'the', u'praise', u'and', u'thanks', u'of', u'the', u'City', u'of', u'Atlanta', u\"''\", u'for', u'the', u'manner', u'in', u'which', u'the', u'election', u'was', u'conducted', u'.'], ...]"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Comparison of Genre based on usage of modal verbs\n",
      "from nltk.corpus import brown\n",
      "news_text = brown.words(categories = 'news')\n",
      "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
      "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
      "for m in modals:\n",
      "    print (m + ':', fdist[m])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('can:', 94)\n",
        "('could:', 87)\n",
        "('may:', 93)\n",
        "('might:', 38)\n",
        "('must:', 53)\n",
        "('will:', 389)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "FreqDist({u'the': 6386, u',': 5188, u'.': 4030, u'of': 2861, u'and': 2186, u'to': 2144, u'a': 2130, u'in': 2020, u'for': 969, u'that': 829, ...})"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystery = brown.words(categories = 'mystery')\n",
      "fdist = nltk.FreqDist(w.lower() for w in mystery)\n",
      "modals = ['what', 'when', 'where', 'who', 'why']\n",
      "for m in modals:\n",
      "    print (m + ':', fdist[m])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('what:', 146)\n",
        "('when:', 154)\n",
        "('where:', 71)\n",
        "('who:', 94)\n",
        "('why:', 52)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "FreqDist({u'.': 3326, u'the': 2817, u',': 2805, u'to': 1294, u'and': 1282, u'a': 1196, u'he': 1076, u'of': 913, u'was': 828, u'``': 740, ...})"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((genre, word) for genre in brown.categories() for word in brown.words(categories = genre)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
      "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.tabulate(conditions = genres, samples = modals)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                 can could  may might must will \n",
        "           news   93   86   66   38   50  389 \n",
        "       religion   82   59   78   12   54   71 \n",
        "        hobbies  268   58  131   22   83  264 \n",
        "science_fiction   16   49    4   12    8   16 \n",
        "        romance   74  193   11   51   45   43 \n",
        "          humor   16   30    8    8    9   13 \n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import reuters\n",
      "reuters.fileids()[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.categories()[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[u'acq', u'alum', u'barley', u'bop', u'carcass']"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.categories('training/9865')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "[u'barley', u'corn', u'grain', u'wheat']"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.categories(['training/9865', 'training/9880'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "[u'barley', u'corn', u'grain', u'money-fx', u'wheat']"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.fileids('barley')[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[u'test/15618', u'test/15649', u'test/15676', u'test/15728', u'test/15871']"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.fileids(['barley', 'corn'])[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "[u'test/14832', u'test/14858', u'test/15033', u'test/15043', u'test/15106']"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words('training/9865')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "[u'FRENCH', u'FREE', u'MARKET', u'CEREAL', u'EXPORT', ...]"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(['training/9865', 'training/9880'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[u'FRENCH', u'FREE', u'MARKET', u'CEREAL', u'EXPORT', ...]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(categories = ['barley'])[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[u'FRENCH', u'FREE', u'MARKET', u'CEREAL', u'EXPORT']"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters.words(categories = ['barley', 'corn'])[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[u'THAI', u'TRADE', u'DEFICIT', u'WIDENS', u'IN']"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import inaugural\n",
      "inaugural.fileids()[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "[u'1789-Washington.txt',\n",
        " u'1793-Washington.txt',\n",
        " u'1797-Adams.txt',\n",
        " u'1801-Jefferson.txt',\n",
        " u'1805-Jefferson.txt']"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[fileid[:4] for fileid in inaugural.fileids()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[u'1789',\n",
        " u'1793',\n",
        " u'1797',\n",
        " u'1801',\n",
        " u'1805',\n",
        " u'1809',\n",
        " u'1813',\n",
        " u'1817',\n",
        " u'1821',\n",
        " u'1825',\n",
        " u'1829',\n",
        " u'1833',\n",
        " u'1837',\n",
        " u'1841',\n",
        " u'1845',\n",
        " u'1849',\n",
        " u'1853',\n",
        " u'1857',\n",
        " u'1861',\n",
        " u'1865',\n",
        " u'1869',\n",
        " u'1873',\n",
        " u'1877',\n",
        " u'1881',\n",
        " u'1885',\n",
        " u'1889',\n",
        " u'1893',\n",
        " u'1897',\n",
        " u'1901',\n",
        " u'1905',\n",
        " u'1909',\n",
        " u'1913',\n",
        " u'1917',\n",
        " u'1921',\n",
        " u'1925',\n",
        " u'1929',\n",
        " u'1933',\n",
        " u'1937',\n",
        " u'1941',\n",
        " u'1945',\n",
        " u'1949',\n",
        " u'1953',\n",
        " u'1957',\n",
        " u'1961',\n",
        " u'1965',\n",
        " u'1969',\n",
        " u'1973',\n",
        " u'1977',\n",
        " u'1981',\n",
        " u'1985',\n",
        " u'1989',\n",
        " u'1993',\n",
        " u'1997',\n",
        " u'2001',\n",
        " u'2005',\n",
        " u'2009']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((target, fileid[:4]) for fileid in inaugural.fileids() for w in inaugural.words(fileid) for target in ['america', 'citizen'] if w.lower().startswith(target))\n",
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import udhr\n",
      "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
      "cfd = nltk.ConditionalFreqDist((lang, len(word)) for lang in languages for word in udhr.words(lang + '-Latin1'))\n",
      "cfd.plot(cumulative = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import udhr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_text = udhr.raw('Ibibio_Efik'+ '-Latin1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.FreqDist(raw_text).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://www.nltk.org/howto/\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['Action', 'Adventure', 'Romantic', 'Thriller']\n",
      "words = ['afraid', 'joke', 'not', 'yes', 'where', 'why', 'when']\n",
      "genre_word = [[genre, word] for genre in genres for word in words]\n",
      "print genre_word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['Action', 'afraid'], ['Action', 'joke'], ['Action', 'not'], ['Action', 'yes'], ['Action', 'where'], ['Action', 'why'], ['Action', 'when'], ['Adventure', 'afraid'], ['Adventure', 'joke'], ['Adventure', 'not'], ['Adventure', 'yes'], ['Adventure', 'where'], ['Adventure', 'why'], ['Adventure', 'when'], ['Romantic', 'afraid'], ['Romantic', 'joke'], ['Romantic', 'not'], ['Romantic', 'yes'], ['Romantic', 'where'], ['Romantic', 'why'], ['Romantic', 'when'], ['Thriller', 'afraid'], ['Thriller', 'joke'], ['Thriller', 'not'], ['Thriller', 'yes'], ['Thriller', 'where'], ['Thriller', 'why'], ['Thriller', 'when']]\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(genre_word)\n",
      "print cfd.conditions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Action', 'Adventure', 'Thriller', 'Romantic']\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd['Adventure']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "FreqDist({'afraid': 1, 'joke': 1, 'when': 1, 'not': 1, 'yes': 1, 'where': 1, 'why': 1})"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd.tabulate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          afraid joke  not when where  why  yes \n",
        "   Action    1    1    1    1    1    1    1 \n",
        "Adventure    1    1    1    1    1    1    1 \n",
        " Romantic    1    1    1    1    1    1    1 \n",
        " Thriller    1    1    1    1    1    1    1 \n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "genres = ['news', 'romance']\n",
      "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent = ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven' 'and', 'the', 'earth']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(nltk.bigrams(sent))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "[('In', 'the'),\n",
        " ('the', 'beginning'),\n",
        " ('beginning', 'God'),\n",
        " ('God', 'created'),\n",
        " ('created', 'the'),\n",
        " ('the', 'heavenand'),\n",
        " ('heavenand', 'the'),\n",
        " ('the', 'earth')]"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_model(cfdist, word, num = 10):\n",
      "    for i in range(num):\n",
      "        print (word)\n",
      "        word = cfdist[word].max()\n",
      "        \n",
      "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
      "bigrams = nltk.bigrams(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(bigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd['living']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "FreqDist({u'creature': 7, u'thing': 4, u'substance': 2, u',': 1, u'.': 1, u'soul': 1})"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<ConditionalFreqDist with 2789 conditions>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generate_model(cfd, 'love')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "love\n",
        "And\n",
        "he\n",
        "said\n",
        ",\n",
        "and\n",
        "the\n",
        "land\n",
        "of\n",
        "the\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "len(stopwords.words('english'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "127"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plural(word):\n",
      "    if word.endswith('y'):\n",
      "        return word[:-1] + 'ies'\n",
      "    elif word[-1] in 'sx' or word[-2:] in ['sh', 'ch']:\n",
      "        return word + 'es'\n",
      "    elif word.endswith('an'):\n",
      "        return word[:-2] + 'en'\n",
      "    else:\n",
      "        return word + 's'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print plural('fairy')\n",
      "print plural('woman')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fairies\n",
        "women\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def unusual_words(text):\n",
      "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
      "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
      "    unusual = text_vocab - english_vocab\n",
      "    return sorted(unusual)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "[u'i',\n",
        " u'me',\n",
        " u'my',\n",
        " u'myself',\n",
        " u'we',\n",
        " u'our',\n",
        " u'ours',\n",
        " u'ourselves',\n",
        " u'you',\n",
        " u'your',\n",
        " u'yours',\n",
        " u'yourself',\n",
        " u'yourselves',\n",
        " u'he',\n",
        " u'him',\n",
        " u'his',\n",
        " u'himself',\n",
        " u'she',\n",
        " u'her',\n",
        " u'hers',\n",
        " u'herself',\n",
        " u'it',\n",
        " u'its',\n",
        " u'itself',\n",
        " u'they',\n",
        " u'them',\n",
        " u'their',\n",
        " u'theirs',\n",
        " u'themselves',\n",
        " u'what',\n",
        " u'which',\n",
        " u'who',\n",
        " u'whom',\n",
        " u'this',\n",
        " u'that',\n",
        " u'these',\n",
        " u'those',\n",
        " u'am',\n",
        " u'is',\n",
        " u'are',\n",
        " u'was',\n",
        " u'were',\n",
        " u'be',\n",
        " u'been',\n",
        " u'being',\n",
        " u'have',\n",
        " u'has',\n",
        " u'had',\n",
        " u'having',\n",
        " u'do',\n",
        " u'does',\n",
        " u'did',\n",
        " u'doing',\n",
        " u'a',\n",
        " u'an',\n",
        " u'the',\n",
        " u'and',\n",
        " u'but',\n",
        " u'if',\n",
        " u'or',\n",
        " u'because',\n",
        " u'as',\n",
        " u'until',\n",
        " u'while',\n",
        " u'of',\n",
        " u'at',\n",
        " u'by',\n",
        " u'for',\n",
        " u'with',\n",
        " u'about',\n",
        " u'against',\n",
        " u'between',\n",
        " u'into',\n",
        " u'through',\n",
        " u'during',\n",
        " u'before',\n",
        " u'after',\n",
        " u'above',\n",
        " u'below',\n",
        " u'to',\n",
        " u'from',\n",
        " u'up',\n",
        " u'down',\n",
        " u'in',\n",
        " u'out',\n",
        " u'on',\n",
        " u'off',\n",
        " u'over',\n",
        " u'under',\n",
        " u'again',\n",
        " u'further',\n",
        " u'then',\n",
        " u'once',\n",
        " u'here',\n",
        " u'there',\n",
        " u'when',\n",
        " u'where',\n",
        " u'why',\n",
        " u'how',\n",
        " u'all',\n",
        " u'any',\n",
        " u'both',\n",
        " u'each',\n",
        " u'few',\n",
        " u'more',\n",
        " u'most',\n",
        " u'other',\n",
        " u'some',\n",
        " u'such',\n",
        " u'no',\n",
        " u'nor',\n",
        " u'not',\n",
        " u'only',\n",
        " u'own',\n",
        " u'same',\n",
        " u'so',\n",
        " u'than',\n",
        " u'too',\n",
        " u'very',\n",
        " u's',\n",
        " u't',\n",
        " u'can',\n",
        " u'will',\n",
        " u'just',\n",
        " u'don',\n",
        " u'should',\n",
        " u'now']"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def content_fraction(text):\n",
      "    stopwords = nltk.corpus.stopwords.words('english')\n",
      "    content = [w for w in text if w.lower() not in stopwords]\n",
      "    return len(content) / float(len(text))\n",
      "\n",
      "content_fraction(nltk.corpus.reuters.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "0.7364374824583169"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "puzzle_letters = nltk.FreqDist('egivrvonl')\n",
      "obligatory = 'r'\n",
      "wordlist = nltk.corpus.words.words()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w in wordlist if len(w) >= 6 and obligatory in w and nltk.FreqDist(w) <= puzzle_letters]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "[u'glover',\n",
        " u'gorlin',\n",
        " u'govern',\n",
        " u'grovel',\n",
        " u'ignore',\n",
        " u'involver',\n",
        " u'lienor',\n",
        " u'linger',\n",
        " u'longer',\n",
        " u'lovering',\n",
        " u'noiler',\n",
        " u'overling',\n",
        " u'region',\n",
        " u'renvoi',\n",
        " u'revolving',\n",
        " u'ringle',\n",
        " u'roving',\n",
        " u'violer',\n",
        " u'virole']"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.FreqDist('revolving') <= puzzle_letters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = nltk.corpus.names\n",
      "names.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "[u'female.txt', u'male.txt']"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "male_names = names.words('male.txt')\n",
      "female_names = names.words('female.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Names that are ambiguous for gender\n",
      "[w for w in male_names if w in female_names]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "[u'Abbey',\n",
        " u'Abbie',\n",
        " u'Abby',\n",
        " u'Addie',\n",
        " u'Adrian',\n",
        " u'Adrien',\n",
        " u'Ajay',\n",
        " u'Alex',\n",
        " u'Alexis',\n",
        " u'Alfie',\n",
        " u'Ali',\n",
        " u'Alix',\n",
        " u'Allie',\n",
        " u'Allyn',\n",
        " u'Andie',\n",
        " u'Andrea',\n",
        " u'Andy',\n",
        " u'Angel',\n",
        " u'Angie',\n",
        " u'Ariel',\n",
        " u'Ashley',\n",
        " u'Aubrey',\n",
        " u'Augustine',\n",
        " u'Austin',\n",
        " u'Averil',\n",
        " u'Barrie',\n",
        " u'Barry',\n",
        " u'Beau',\n",
        " u'Bennie',\n",
        " u'Benny',\n",
        " u'Bernie',\n",
        " u'Bert',\n",
        " u'Bertie',\n",
        " u'Bill',\n",
        " u'Billie',\n",
        " u'Billy',\n",
        " u'Blair',\n",
        " u'Blake',\n",
        " u'Bo',\n",
        " u'Bobbie',\n",
        " u'Bobby',\n",
        " u'Brandy',\n",
        " u'Brett',\n",
        " u'Britt',\n",
        " u'Brook',\n",
        " u'Brooke',\n",
        " u'Brooks',\n",
        " u'Bryn',\n",
        " u'Cal',\n",
        " u'Cam',\n",
        " u'Cammy',\n",
        " u'Carey',\n",
        " u'Carlie',\n",
        " u'Carlin',\n",
        " u'Carmine',\n",
        " u'Carroll',\n",
        " u'Cary',\n",
        " u'Caryl',\n",
        " u'Casey',\n",
        " u'Cass',\n",
        " u'Cat',\n",
        " u'Cecil',\n",
        " u'Chad',\n",
        " u'Chris',\n",
        " u'Chrissy',\n",
        " u'Christian',\n",
        " u'Christie',\n",
        " u'Christy',\n",
        " u'Clair',\n",
        " u'Claire',\n",
        " u'Clare',\n",
        " u'Claude',\n",
        " u'Clem',\n",
        " u'Clemmie',\n",
        " u'Cody',\n",
        " u'Connie',\n",
        " u'Constantine',\n",
        " u'Corey',\n",
        " u'Corrie',\n",
        " u'Cory',\n",
        " u'Courtney',\n",
        " u'Cris',\n",
        " u'Daffy',\n",
        " u'Dale',\n",
        " u'Dallas',\n",
        " u'Dana',\n",
        " u'Dani',\n",
        " u'Daniel',\n",
        " u'Dannie',\n",
        " u'Danny',\n",
        " u'Darby',\n",
        " u'Darcy',\n",
        " u'Darryl',\n",
        " u'Daryl',\n",
        " u'Deane',\n",
        " u'Del',\n",
        " u'Dell',\n",
        " u'Demetris',\n",
        " u'Dennie',\n",
        " u'Denny',\n",
        " u'Devin',\n",
        " u'Devon',\n",
        " u'Dion',\n",
        " u'Dionis',\n",
        " u'Dominique',\n",
        " u'Donnie',\n",
        " u'Donny',\n",
        " u'Dorian',\n",
        " u'Dory',\n",
        " u'Drew',\n",
        " u'Eddie',\n",
        " u'Eddy',\n",
        " u'Edie',\n",
        " u'Elisha',\n",
        " u'Emmy',\n",
        " u'Erin',\n",
        " u'Esme',\n",
        " u'Evelyn',\n",
        " u'Felice',\n",
        " u'Fran',\n",
        " u'Francis',\n",
        " u'Frank',\n",
        " u'Frankie',\n",
        " u'Franky',\n",
        " u'Fred',\n",
        " u'Freddie',\n",
        " u'Freddy',\n",
        " u'Gabriel',\n",
        " u'Gabriell',\n",
        " u'Gail',\n",
        " u'Gale',\n",
        " u'Gay',\n",
        " u'Gayle',\n",
        " u'Gene',\n",
        " u'George',\n",
        " u'Georgia',\n",
        " u'Georgie',\n",
        " u'Geri',\n",
        " u'Germaine',\n",
        " u'Gerri',\n",
        " u'Gerry',\n",
        " u'Gill',\n",
        " u'Ginger',\n",
        " u'Glen',\n",
        " u'Glenn',\n",
        " u'Grace',\n",
        " u'Gretchen',\n",
        " u'Gus',\n",
        " u'Haleigh',\n",
        " u'Haley',\n",
        " u'Hannibal',\n",
        " u'Harley',\n",
        " u'Hazel',\n",
        " u'Heath',\n",
        " u'Henrie',\n",
        " u'Hilary',\n",
        " u'Hillary',\n",
        " u'Holly',\n",
        " u'Ike',\n",
        " u'Ikey',\n",
        " u'Ira',\n",
        " u'Isa',\n",
        " u'Isador',\n",
        " u'Isadore',\n",
        " u'Jackie',\n",
        " u'Jaime',\n",
        " u'Jamie',\n",
        " u'Jan',\n",
        " u'Jean',\n",
        " u'Jere',\n",
        " u'Jermaine',\n",
        " u'Jerrie',\n",
        " u'Jerry',\n",
        " u'Jess',\n",
        " u'Jesse',\n",
        " u'Jessie',\n",
        " u'Jo',\n",
        " u'Jodi',\n",
        " u'Jodie',\n",
        " u'Jody',\n",
        " u'Joey',\n",
        " u'Jordan',\n",
        " u'Juanita',\n",
        " u'Jude',\n",
        " u'Judith',\n",
        " u'Judy',\n",
        " u'Julie',\n",
        " u'Justin',\n",
        " u'Karel',\n",
        " u'Kellen',\n",
        " u'Kelley',\n",
        " u'Kelly',\n",
        " u'Kelsey',\n",
        " u'Kerry',\n",
        " u'Kim',\n",
        " u'Kip',\n",
        " u'Kirby',\n",
        " u'Kit',\n",
        " u'Kris',\n",
        " u'Kyle',\n",
        " u'Lane',\n",
        " u'Lanny',\n",
        " u'Lauren',\n",
        " u'Laurie',\n",
        " u'Lee',\n",
        " u'Leigh',\n",
        " u'Leland',\n",
        " u'Lesley',\n",
        " u'Leslie',\n",
        " u'Lin',\n",
        " u'Lind',\n",
        " u'Lindsay',\n",
        " u'Lindsey',\n",
        " u'Lindy',\n",
        " u'Lonnie',\n",
        " u'Loren',\n",
        " u'Lorne',\n",
        " u'Lorrie',\n",
        " u'Lou',\n",
        " u'Luce',\n",
        " u'Lyn',\n",
        " u'Lynn',\n",
        " u'Maddie',\n",
        " u'Maddy',\n",
        " u'Marietta',\n",
        " u'Marion',\n",
        " u'Marlo',\n",
        " u'Martie',\n",
        " u'Marty',\n",
        " u'Mattie',\n",
        " u'Matty',\n",
        " u'Maurise',\n",
        " u'Max',\n",
        " u'Maxie',\n",
        " u'Mead',\n",
        " u'Meade',\n",
        " u'Mel',\n",
        " u'Meredith',\n",
        " u'Merle',\n",
        " u'Merrill',\n",
        " u'Merry',\n",
        " u'Meryl',\n",
        " u'Michal',\n",
        " u'Michel',\n",
        " u'Michele',\n",
        " u'Mickie',\n",
        " u'Micky',\n",
        " u'Millicent',\n",
        " u'Morgan',\n",
        " u'Morlee',\n",
        " u'Muffin',\n",
        " u'Nat',\n",
        " u'Nichole',\n",
        " u'Nickie',\n",
        " u'Nicky',\n",
        " u'Niki',\n",
        " u'Nikki',\n",
        " u'Noel',\n",
        " u'Ollie',\n",
        " u'Page',\n",
        " u'Paige',\n",
        " u'Pat',\n",
        " u'Patrice',\n",
        " u'Patsy',\n",
        " u'Pattie',\n",
        " u'Patty',\n",
        " u'Pen',\n",
        " u'Pennie',\n",
        " u'Penny',\n",
        " u'Perry',\n",
        " u'Phil',\n",
        " u'Pooh',\n",
        " u'Quentin',\n",
        " u'Quinn',\n",
        " u'Randi',\n",
        " u'Randie',\n",
        " u'Randy',\n",
        " u'Ray',\n",
        " u'Regan',\n",
        " u'Reggie',\n",
        " u'Rene',\n",
        " u'Rey',\n",
        " u'Ricki',\n",
        " u'Rickie',\n",
        " u'Ricky',\n",
        " u'Rikki',\n",
        " u'Robbie',\n",
        " u'Robin',\n",
        " u'Ronnie',\n",
        " u'Ronny',\n",
        " u'Rory',\n",
        " u'Ruby',\n",
        " u'Sal',\n",
        " u'Sam',\n",
        " u'Sammy',\n",
        " u'Sandy',\n",
        " u'Sascha',\n",
        " u'Sasha',\n",
        " u'Saundra',\n",
        " u'Sayre',\n",
        " u'Scotty',\n",
        " u'Sean',\n",
        " u'Shaine',\n",
        " u'Shane',\n",
        " u'Shannon',\n",
        " u'Shaun',\n",
        " u'Shawn',\n",
        " u'Shay',\n",
        " u'Shayne',\n",
        " u'Shea',\n",
        " u'Shelby',\n",
        " u'Shell',\n",
        " u'Shelley',\n",
        " u'Sibyl',\n",
        " u'Simone',\n",
        " u'Sonnie',\n",
        " u'Sonny',\n",
        " u'Stacy',\n",
        " u'Sunny',\n",
        " u'Sydney',\n",
        " u'Tabbie',\n",
        " u'Tabby',\n",
        " u'Tallie',\n",
        " u'Tally',\n",
        " u'Tammie',\n",
        " u'Tammy',\n",
        " u'Tate',\n",
        " u'Ted',\n",
        " u'Teddie',\n",
        " u'Teddy',\n",
        " u'Terri',\n",
        " u'Terry',\n",
        " u'Theo',\n",
        " u'Tim',\n",
        " u'Timmie',\n",
        " u'Timmy',\n",
        " u'Tobe',\n",
        " u'Tobie',\n",
        " u'Toby',\n",
        " u'Tommie',\n",
        " u'Tommy',\n",
        " u'Tony',\n",
        " u'Torey',\n",
        " u'Trace',\n",
        " u'Tracey',\n",
        " u'Tracie',\n",
        " u'Tracy',\n",
        " u'Val',\n",
        " u'Vale',\n",
        " u'Valentine',\n",
        " u'Van',\n",
        " u'Vin',\n",
        " u'Vinnie',\n",
        " u'Vinny',\n",
        " u'Virgie',\n",
        " u'Wallie',\n",
        " u'Wallis',\n",
        " u'Wally',\n",
        " u'Whitney',\n",
        " u'Willi',\n",
        " u'Willie',\n",
        " u'Willy',\n",
        " u'Winnie',\n",
        " u'Winny',\n",
        " u'Wynn']"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist((fileid, name) for fileid in names.fileids() for name in names.words(fileid))\n",
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairs = [(fileid, name[-1]) for fileid in names.fileids() for name in names.words(fileid)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.ConditionalFreqDist(pairs).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entries = nltk.corpus.cmudict.entries()\n",
      "len(entries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "133737"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for entry in entries[50000: 50020]:\n",
      "    print entry"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'griffon', [u'G', u'R', u'IH1', u'F', u'AH0', u'N'])\n",
        "(u'griffy', [u'G', u'R', u'IH1', u'F', u'IY0'])\n",
        "(u'grigas', [u'G', u'R', u'AY1', u'G', u'AH0', u'Z'])\n",
        "(u'grigg', [u'G', u'R', u'IH1', u'G'])\n",
        "(u'griggs', [u'G', u'R', u'IH1', u'G', u'Z'])\n",
        "(u'griggy', [u'G', u'R', u'IH1', u'G', u'IY0'])\n",
        "(u'grignon', [u'G', u'R', u'IH1', u'G', u'N', u'AH0', u'N'])\n",
        "(u'grigoli', [u'G', u'R', u'IH0', u'G', u'OW1', u'L', u'IY0'])\n",
        "(u'grigorovich', [u'G', u'R', u'IH0', u'G', u'AO1', u'R', u'AH0', u'V', u'IH0', u'CH'])\n",
        "(u'grigory', [u'G', u'R', u'EH1', u'G', u'ER0', u'IY0'])\n",
        "(u'grigory', [u'G', u'R', u'IY1', u'G', u'ER0', u'IY0'])\n",
        "(u'grigoryant', [u'G', u'R', u'IH0', u'G', u'AO1', u'R', u'Y', u'AE0', u'N', u'T'])\n",
        "(u'grigoryants', [u'G', u'R', u'IH0', u'G', u'AO1', u'R', u'Y', u'AE0', u'N', u'T', u'S'])\n",
        "(u'grigsby', [u'G', u'R', u'IH1', u'G', u'Z', u'B', u'IY0'])\n",
        "(u'grijalva', [u'G', u'R', u'IY0', u'Y', u'AA1', u'L', u'V', u'AH0'])\n",
        "(u'grill', [u'G', u'R', u'IH1', u'L'])\n",
        "(u'grille', [u'G', u'R', u'IH1', u'L'])\n",
        "(u'grilled', [u'G', u'R', u'IH1', u'L', u'D'])\n",
        "(u'grilli', [u'G', u'R', u'IH1', u'L', u'IY0'])\n",
        "(u'grilling', [u'G', u'R', u'IH1', u'L', u'IH0', u'NG'])\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word, pron in entries:\n",
      "    if len(pron) == 3:\n",
      "        ph1, ph2, ph3 = pron\n",
      "        if ph1 == 'P' and ph3 == 'T':\n",
      "            print (word, ph2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'pait', u'EY1')\n",
        "(u'pat', u'AE1')\n",
        "(u'pate', u'EY1')\n",
        "(u'patt', u'AE1')\n",
        "(u'peart', u'ER1')\n",
        "(u'peat', u'IY1')\n",
        "(u'peet', u'IY1')\n",
        "(u'peete', u'IY1')\n",
        "(u'pert', u'ER1')\n",
        "(u'pet', u'EH1')\n",
        "(u'pete', u'IY1')\n",
        "(u'pett', u'EH1')\n",
        "(u'piet', u'IY1')\n",
        "(u'piette', u'IY1')\n",
        "(u'pit', u'IH1')\n",
        "(u'pitt', u'IH1')\n",
        "(u'pot', u'AA1')\n",
        "(u'pote', u'OW1')\n",
        "(u'pott', u'AA1')\n",
        "(u'pout', u'AW1')\n",
        "(u'puett', u'UW1')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'purt', u'ER1')\n",
        "(u'put', u'UH1')\n",
        "(u'putt', u'AH1')\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syllable = ['N', 'IHO', 'K', 'S']\n",
      "[word for word, pron in entries if pron[-4:] == syllable]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[w for w, pron in entries if pron[-1] == 'M' and w[-1] == 'n']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "[u'autumn', u'column', u'condemn', u'damn', u'goddamn', u'hymn', u'solemn']"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set(w[:2] for w, pron in entries if pron[0] == 'N' and w[0] != 'n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "{u'gn', u'kn', u'mn', u'pn'}"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import wordnet as wn\n",
      "wn.synset('car.n.01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "Synset('car.n.01')"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').lemma_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "[u'car', u'auto', u'automobile', u'machine', u'motorcar']"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').definition()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "u'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').examples()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "[u'he needs a car to get to work']"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').lemmas()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "[Lemma('car.n.01.car'),\n",
        " Lemma('car.n.01.auto'),\n",
        " Lemma('car.n.01.automobile'),\n",
        " Lemma('car.n.01.machine'),\n",
        " Lemma('car.n.01.motorcar')]"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemma('car.n.01.motorcar').name()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "u'motorcar'"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synsets('car')\n",
      "for s in wn.synsets('car'):\n",
      "    print s.lemma_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'car', u'auto', u'automobile', u'machine', u'motorcar']\n",
        "[u'car', u'railcar', u'railway_car', u'railroad_car']\n",
        "[u'car', u'gondola']\n",
        "[u'car', u'elevator_car']\n",
        "[u'cable_car', u'car']\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.lemmas('dish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "[Lemma('dish.n.01.dish'),\n",
        " Lemma('dish.n.02.dish'),\n",
        " Lemma('dish.n.03.dish'),\n",
        " Lemma('smasher.n.02.dish'),\n",
        " Lemma('dish.n.05.dish'),\n",
        " Lemma('cup_of_tea.n.01.dish'),\n",
        " Lemma('serve.v.06.dish'),\n",
        " Lemma('dish.v.02.dish')]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}